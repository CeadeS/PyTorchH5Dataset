{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 999Time for 1000 epochs was 10.851427555084229\n",
      "tensor(-1., device='cuda:0') tensor(1., device='cuda:0')\n",
      "tensor(247327.0312, device='cuda:0', grad_fn=<SumBackward0>) 5000\n",
      " 999Time for 1000 epochs was 11.825344324111938\n",
      "tensor(0., device='cuda:0') tensor(1., device='cuda:0')\n",
      "tensor(228311.3125, device='cuda:0', grad_fn=<SumBackward0>) 5000\n"
     ]
    }
   ],
   "source": [
    "from pytorch_h5dataset.benchmark import Benchmarker, BenchmarkDataset\n",
    "from pytorch_h5dataset import H5DataLoader\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, float32, as_tensor\n",
    "from torch.nn import MSELoss\n",
    "from time import time\n",
    "from numpy import prod\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "benchmarkdataset = BenchmarkDataset(dataset_root=\"H:/Datasets/coco2017\")\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 1000\n",
    "device = 'cuda:0'\n",
    "\n",
    "benchmarker1 = Benchmarker()\n",
    "dataLoader1 = benchmarker1.decorate_iterator_class(H5DataLoader)(dataset=benchmarkdataset.h5dataset,\n",
    "                                                                          device=device, batch_size=batch_size,\n",
    "                                                                        return_meta_indices=True,\n",
    "                                                                          pin_memory=True,\n",
    "                                                                           num_workers=0,)\n",
    "\n",
    "benchmarker2 = Benchmarker()\n",
    "dataloader2 = benchmarker2.decorate_iterator_class(DataLoader)(benchmarkdataset.imageFolderDataset,\n",
    "                                                               batch_size=batch_size,\n",
    "                                                               num_workers=4,\n",
    "                                                               pin_memory=True)\n",
    "\n",
    "criterion = MSELoss()\n",
    "\n",
    "\n",
    "for benchmarker, dataloader in ((benchmarker1, dataLoader1) , (benchmarker2,dataloader2)):\n",
    "    benchmarker.reset_benchmarker()\n",
    "    model = nn.Linear(3 * 244 * 244, 1000).to(device)\n",
    "    sum_loss = 0\n",
    "    num_out = 0\n",
    "    t0 = time()\n",
    "    for e in range(epochs):\n",
    "        print('\\r',e, end='')\n",
    "        for sample, label in dataloader:\n",
    "            if isinstance(label, tuple):\n",
    "                label = label[0]\n",
    "            x = sample.to(device).view(sample.size(0),-1)\n",
    "            y = as_tensor(label.view(-1), dtype=float32,device=device).requires_grad_(True)\n",
    "            y_out = model(x).argmax(1).float()\n",
    "            num_out += prod(y_out.shape)\n",
    "            loss = criterion(y, y_out)\n",
    "            loss = loss.sum()\n",
    "            sum_loss += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "    print(f\"Time for {epochs} epochs was {time() - t0}\")\n",
    "    print(x.min(),x.max())\n",
    "    print(loss, num_out)\n",
    "    del dataloader, x,y, model, loss, sum_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "df = benchmarker1.get_stats_df()\n",
    "sns.set()\n",
    "legend = ['proc_cpu_util','proc_disk_io_bytes_read','proc_disk_io_count_read','proc_cpu_time_user', 'proc_mem_bytes_vms', 'sys_net_io_bytes_recv']\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "for col in legend:\n",
    "    plt.plot(df[col]/ max(abs(df[col])))\n",
    "plt.legend(legend)\n",
    "plt.show()\n",
    "legend = ['proc_cpu_util','proc_disk_io_bytes_read_acc','proc_disk_io_count_read_acc','proc_cpu_time_user_acc', 'proc_mem_bytes_vms_acc', 'sys_net_io_bytes_recv_acc']\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "for col in legend:\n",
    "    plt.plot(df[col])\n",
    "plt.legend(legend)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = benchmarker2.get_stats_df()\n",
    "sns.set()\n",
    "legend = ['proc_cpu_util','proc_disk_io_bytes_read','proc_disk_io_count_read','proc_cpu_time_user', 'proc_mem_bytes_vms', 'sys_net_io_bytes_recv']\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "for col in legend:\n",
    "    plt.plot(df[col]/ max(abs(df[col])))\n",
    "plt.legend(legend)\n",
    "plt.show()\n",
    "legend = ['proc_cpu_util','proc_disk_io_bytes_read_acc','proc_disk_io_count_read_acc','proc_cpu_time_user_acc', 'proc_mem_bytes_vms_acc', 'sys_net_io_bytes_recv_acc']\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "for col in legend:\n",
    "    plt.plot(df[col])\n",
    "plt.legend(legend)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}